{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu8y1MVOu6c7"
      },
      "source": [
        "Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVxrrh5a5XQD",
        "outputId": "78f3be01-da40-4a32-f9dc-ce78287df3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter git token··········\n",
            "Cloning into 'AIPI-531-Final-Project'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 96 (delta 40), reused 30 (delta 28), pack-reused 45\u001b[K\n",
            "Unpacking objects: 100% (96/96), 77.17 MiB | 11.34 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# # Clone GitHub files to colab workspace\n",
        "git_user = \"sfhorng\" # Enter user or organization name\n",
        "repo_name = \"AIPI-531-Final-Project\" # Enter repo name\n",
        "git_token = getpass.getpass(\"enter git token\") # Enter your github token \n",
        "git_path = f\"https://{git_token}@github.com/{git_user}/{repo_name}.git\"\n",
        "!git clone \"{git_path}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpH3eaCvvDYd"
      },
      "source": [
        "Install needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLabrBDTxaVH",
        "outputId": "f72fdd7d-48ba-48e5-e036-a9b8d2091273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from -r /content/AIPI-531-Final-Project/requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from -r /content/AIPI-531-Final-Project/requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from -r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from -r /content/AIPI-531-Final-Project/requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from trfl->-r /content/AIPI-531-Final-Project/requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from trfl->-r /content/AIPI-531-Final-Project/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/dist-packages (from trfl->-r /content/AIPI-531-Final-Project/requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from trfl->-r /content/AIPI-531-Final-Project/requirements.txt (line 1)) (0.1.8)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->-r /content/AIPI-531-Final-Project/requirements.txt (line 3)) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->-r /content/AIPI-531-Final-Project/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (3.20.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (16.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (0.32.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (1.53.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.12.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (3.8.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (23.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (67.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.12.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r /content/AIPI-531-Final-Project/requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r /content/AIPI-531-Final-Project/requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r /content/AIPI-531-Final-Project/requirements.txt (line 5)) (1.10.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (0.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.27.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (6.4.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r /content/AIPI-531-Final-Project/requirements.txt (line 4)) (3.2.2)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies from requirements.txt file\n",
        "REPO_PATH = os.path.join(os.getcwd(), repo_name)\n",
        "%pip install -r {os.path.join(REPO_PATH, 'requirements.txt')}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nucaMUabvYiK"
      },
      "source": [
        "Authenticate before using the Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67I66yAntOno"
      },
      "outputs": [],
      "source": [
        "# Upload kaggle.json credentials for downloading with the API\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HGkCERV-vfhI"
      },
      "source": [
        "Download dataset and create sessions, item features, popularity dictionary and replay buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H__buga20FD-",
        "outputId": "f3c35bc5-3fcc-4b96-eb03-a72a65347927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-25 14:01:12.319920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-25 14:01:13.284977: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Directory passed in for Retail Rocket data: /content/AIPI-531-Final-Project/Retail_Rocket_Data/data\n",
            "Downloading ecommerce-dataset.zip to /content\n",
            " 95% 276M/291M [00:04<00:00, 59.4MB/s]\n",
            "100% 291M/291M [00:05<00:00, 60.9MB/s]\n",
            "Archive:  ecommerce-dataset.zip\n",
            "  inflating: /content/AIPI-531-Final-Project/Retail_Rocket_Data/data/category_tree.csv  \n",
            "  inflating: /content/AIPI-531-Final-Project/Retail_Rocket_Data/data/events.csv  \n",
            "  inflating: /content/AIPI-531-Final-Project/Retail_Rocket_Data/data/item_properties_part1.csv  \n",
            "  inflating: /content/AIPI-531-Final-Project/Retail_Rocket_Data/data/item_properties_part2.csv  \n",
            "Finished downloading to /content/AIPI-531-Final-Project/Retail_Rocket_Data/data\n",
            "Started to split the sorted events into train, validation, and test\n",
            "Finished splitting into train, validation, and test sessions\n",
            "Started to create item features\n",
            "/content/AIPI-531-Final-Project/Retail_Rocket_Data/src/item_features.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  item_properties_df['itemid'] = item_encoder.transform(\n",
            "Finished creating the item features\n",
            "Started to create the popularity dictionary\n",
            "100% 1184212/1184212 [00:00<00:00, 1926202.08it/s]\n",
            "Finished creating the popularity dictionary\n",
            "Started to create the replay buffer\n",
            "100% 152056/152056 [00:55<00:00, 2722.52it/s]\n",
            "   state_size  item_num\n",
            "0          10     65664\n",
            "Finished creating the replay buffer\n"
          ]
        }
      ],
      "source": [
        "RR_DIR = f'{REPO_PATH}/Retail_Rocket_Data'\n",
        "!python \"{RR_DIR}/src/main_setup.py\" --data_directory='{RR_DIR}/data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydt7S2Vgvtwj"
      },
      "source": [
        "Train and evaluate on validation sessions, then evaluate on test sessions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHTt1pJhArX-",
        "outputId": "5488bbf0-2e1c-47ef-a5fc-3fd94654452d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AIPI-531-Final-Project/Retail_Rocket_Data/src\n",
            "2023-04-25 14:17:12.887414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/AIPI-531-Final-Project/Retail_Rocket_Data/src/SNQN_new.py:83: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/AIPI-531-Final-Project/Retail_Rocket_Data/src/SNQN_new.py:82: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/keras/layers/rnn/legacy_cells.py:584: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/keras/layers/rnn/legacy_cells.py:598: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/AIPI-531-Final-Project/Retail_Rocket_Data/src/SNQN_new.py:210: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/AIPI-531-Final-Project/Retail_Rocket_Data/src/SNQN_new.py:213: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/AIPI-531-Final-Project/Retail_Rocket_Data/src/SNQN_new.py:219: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  item_embeddings_and_bias = tf.compat.v1.layers.dense(\n",
            "2023-04-25 14:17:20.999059: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Number of rows: 949444\n",
            "Number of batches: 3708\n",
            "Epoch 1/15\n",
            "the loss in 200th batch is: 17.751032\n",
            "the loss in 400th batch is: 15.382178\n",
            "the loss in 600th batch is: 22.678125\n",
            "the loss in 800th batch is: 15.476508\n",
            "the loss in 1000th batch is: 13.497988\n",
            "the loss in 1200th batch is: 14.349492\n",
            "the loss in 1400th batch is: 13.332886\n",
            "the loss in 1600th batch is: 13.877462\n",
            "the loss in 1800th batch is: 11.802645\n",
            "the loss in 2000th batch is: 11.296387\n",
            "the loss in 2200th batch is: 10.995920\n",
            "the loss in 2400th batch is: 11.301168\n",
            "the loss in 2600th batch is: 11.151441\n",
            "the loss in 2800th batch is: 11.149332\n",
            "the loss in 3000th batch is: 14.224125\n",
            "the loss in 3200th batch is: 11.145919\n",
            "the loss in 3400th batch is: 11.539567\n",
            "the loss in 3600th batch is: 10.646798\n",
            "Epoch 2/15\n",
            "the loss in 3800th batch is: 10.691645\n",
            "the loss in 4000th batch is: 10.474154\n",
            "the loss in 4200th batch is: 10.442616\n",
            "the loss in 4400th batch is: 10.861703\n",
            "the loss in 4600th batch is: 10.855351\n",
            "the loss in 4800th batch is: 10.750610\n",
            "the loss in 5000th batch is: 10.571358\n",
            "the loss in 5200th batch is: 10.794714\n",
            "the loss in 5400th batch is: 10.525166\n",
            "the loss in 5600th batch is: 10.935616\n",
            "the loss in 5800th batch is: 10.581973\n",
            "the loss in 6000th batch is: 10.547483\n",
            "the loss in 6200th batch is: 10.416378\n",
            "the loss in 6400th batch is: 10.385213\n",
            "the loss in 6600th batch is: 10.896640\n",
            "the loss in 6800th batch is: 10.312653\n",
            "the loss in 7000th batch is: 10.634289\n",
            "the loss in 7200th batch is: 10.690149\n",
            "the loss in 7400th batch is: 10.072482\n",
            "Epoch 3/15\n",
            "the loss in 7600th batch is: 10.464400\n",
            "the loss in 7800th batch is: 11.500135\n",
            "the loss in 8000th batch is: 10.688259\n",
            "the loss in 8200th batch is: 10.412509\n",
            "the loss in 8400th batch is: 10.406790\n",
            "the loss in 8600th batch is: 10.524922\n",
            "the loss in 8800th batch is: 10.465929\n",
            "the loss in 9000th batch is: 10.529019\n",
            "Evaluating with val sessions\n",
            "evaluated ID count is 0 / 19007 total\n",
            "evaluated ID count is 1000 / 19007 total\n",
            "evaluated ID count is 2000 / 19007 total\n",
            "evaluated ID count is 3000 / 19007 total\n",
            "evaluated ID count is 4000 / 19007 total\n",
            "evaluated ID count is 5000 / 19007 total\n",
            "evaluated ID count is 6000 / 19007 total\n",
            "evaluated ID count is 7000 / 19007 total\n",
            "evaluated ID count is 8000 / 19007 total\n",
            "evaluated ID count is 9000 / 19007 total\n",
            "evaluated ID count is 10000 / 19007 total\n",
            "evaluated ID count is 11000 / 19007 total\n",
            "evaluated ID count is 12000 / 19007 total\n",
            "evaluated ID count is 13000 / 19007 total\n",
            "evaluated ID count is 14000 / 19007 total\n",
            "evaluated ID count is 15000 / 19007 total\n",
            "evaluated ID count is 16000 / 19007 total\n",
            "evaluated ID count is 17000 / 19007 total\n",
            "evaluated ID count is 18000 / 19007 total\n",
            "evaluated ID count is 19000 / 19007 total\n",
            "#############################################################\n",
            "total clicks: 113704, total purchase:5707\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 533.800000\n",
            "clicks hr ndcg @ 5 : 0.015074, 0.010990\n",
            "purchase hr and ndcg @5 : 0.033468, 0.026462\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 685.000000\n",
            "clicks hr ndcg @ 10 : 0.020052, 0.012599\n",
            "purchase hr and ndcg @10 : 0.040126, 0.028602\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 811.600000\n",
            "clicks hr ndcg @ 15 : 0.024740, 0.013838\n",
            "purchase hr and ndcg @15 : 0.043631, 0.029540\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 954.000000\n",
            "clicks hr ndcg @ 20 : 0.028891, 0.014818\n",
            "purchase hr and ndcg @20 : 0.052041, 0.031557\n",
            "#############################################################\n",
            "the loss in 9200th batch is: 10.450772\n",
            "the loss in 9400th batch is: 10.294721\n",
            "the loss in 9600th batch is: 10.414516\n",
            "the loss in 9800th batch is: 10.205201\n",
            "the loss in 10000th batch is: 10.482038\n",
            "the loss in 10200th batch is: 10.069245\n",
            "the loss in 10400th batch is: 10.202465\n",
            "the loss in 10600th batch is: 10.241399\n",
            "the loss in 10800th batch is: 10.411109\n",
            "the loss in 11000th batch is: 10.448524\n",
            "Epoch 4/15\n",
            "the loss in 11200th batch is: 10.030994\n",
            "the loss in 11400th batch is: 10.212817\n",
            "the loss in 11600th batch is: 10.714625\n",
            "the loss in 11800th batch is: 10.096558\n",
            "the loss in 12000th batch is: 10.266729\n",
            "the loss in 12200th batch is: 10.218641\n",
            "the loss in 12400th batch is: 10.238444\n",
            "the loss in 12600th batch is: 10.149717\n",
            "the loss in 12800th batch is: 10.355912\n",
            "the loss in 13000th batch is: 10.810828\n",
            "the loss in 13200th batch is: 10.257976\n",
            "the loss in 13400th batch is: 10.344711\n",
            "the loss in 13600th batch is: 10.219181\n",
            "the loss in 13800th batch is: 10.335552\n",
            "the loss in 14000th batch is: 10.054775\n",
            "the loss in 14200th batch is: 10.295783\n",
            "the loss in 14400th batch is: 10.228653\n",
            "the loss in 14600th batch is: 10.011257\n",
            "the loss in 14800th batch is: 9.975849\n",
            "Epoch 5/15\n",
            "the loss in 15000th batch is: 10.254714\n",
            "the loss in 15200th batch is: 10.055668\n",
            "the loss in 15400th batch is: 9.923301\n",
            "the loss in 15600th batch is: 10.176695\n",
            "the loss in 15800th batch is: 10.780286\n",
            "the loss in 16000th batch is: 10.012799\n",
            "the loss in 16200th batch is: 9.774284\n",
            "the loss in 16400th batch is: 10.987638\n",
            "the loss in 16600th batch is: 10.057278\n",
            "the loss in 16800th batch is: 10.109499\n",
            "the loss in 17000th batch is: 9.672244\n",
            "the loss in 17200th batch is: 10.075267\n",
            "the loss in 17400th batch is: 9.991279\n",
            "the loss in 17600th batch is: 9.920790\n",
            "the loss in 17800th batch is: 10.548075\n",
            "the loss in 18000th batch is: 9.972063\n",
            "Evaluating with val sessions\n",
            "evaluated ID count is 0 / 19007 total\n",
            "evaluated ID count is 1000 / 19007 total\n",
            "evaluated ID count is 2000 / 19007 total\n",
            "evaluated ID count is 3000 / 19007 total\n",
            "evaluated ID count is 4000 / 19007 total\n",
            "evaluated ID count is 5000 / 19007 total\n",
            "evaluated ID count is 6000 / 19007 total\n",
            "evaluated ID count is 7000 / 19007 total\n",
            "evaluated ID count is 8000 / 19007 total\n",
            "evaluated ID count is 9000 / 19007 total\n",
            "evaluated ID count is 10000 / 19007 total\n",
            "evaluated ID count is 11000 / 19007 total\n",
            "evaluated ID count is 12000 / 19007 total\n",
            "evaluated ID count is 13000 / 19007 total\n",
            "evaluated ID count is 14000 / 19007 total\n",
            "evaluated ID count is 15000 / 19007 total\n",
            "evaluated ID count is 16000 / 19007 total\n",
            "evaluated ID count is 17000 / 19007 total\n",
            "evaluated ID count is 18000 / 19007 total\n",
            "evaluated ID count is 19000 / 19007 total\n",
            "#############################################################\n",
            "total clicks: 113704, total purchase:5707\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1701.600000\n",
            "clicks hr ndcg @ 5 : 0.049101, 0.036334\n",
            "purchase hr and ndcg @5 : 0.102506, 0.079432\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2141.800000\n",
            "clicks hr ndcg @ 10 : 0.062918, 0.040796\n",
            "purchase hr and ndcg @10 : 0.124584, 0.086563\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 2384.600000\n",
            "clicks hr ndcg @ 15 : 0.070736, 0.042866\n",
            "purchase hr and ndcg @15 : 0.135973, 0.089570\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 2600.800000\n",
            "clicks hr ndcg @ 20 : 0.077649, 0.044497\n",
            "purchase hr and ndcg @20 : 0.146312, 0.092016\n",
            "#############################################################\n",
            "the loss in 18200th batch is: 9.904963\n",
            "the loss in 18400th batch is: 9.569056\n",
            "Epoch 6/15\n",
            "the loss in 18600th batch is: 10.708107\n",
            "the loss in 18800th batch is: 9.441801\n",
            "the loss in 19000th batch is: 9.731384\n",
            "the loss in 19200th batch is: 10.370209\n",
            "the loss in 19400th batch is: 10.099491\n",
            "the loss in 19600th batch is: 9.711707\n",
            "the loss in 19800th batch is: 10.673781\n",
            "the loss in 20000th batch is: 9.704412\n",
            "the loss in 20200th batch is: 9.914235\n",
            "the loss in 20400th batch is: 9.833152\n",
            "the loss in 20600th batch is: 9.899391\n",
            "the loss in 20800th batch is: 9.764757\n",
            "the loss in 21000th batch is: 9.715031\n",
            "the loss in 21200th batch is: 9.696793\n",
            "the loss in 21400th batch is: 9.441251\n",
            "the loss in 21600th batch is: 9.590424\n",
            "the loss in 21800th batch is: 9.592531\n",
            "the loss in 22000th batch is: 9.811982\n",
            "the loss in 22200th batch is: 9.523033\n",
            "Epoch 7/15\n",
            "the loss in 22400th batch is: 9.503598\n",
            "the loss in 22600th batch is: 9.475024\n",
            "the loss in 22800th batch is: 9.431620\n",
            "the loss in 23000th batch is: 9.750027\n",
            "the loss in 23200th batch is: 9.736534\n",
            "the loss in 23400th batch is: 9.448285\n",
            "the loss in 23600th batch is: 9.417017\n",
            "the loss in 23800th batch is: 9.210722\n",
            "the loss in 24000th batch is: 9.507038\n",
            "the loss in 24200th batch is: 9.531767\n",
            "the loss in 24400th batch is: 9.473098\n",
            "the loss in 24600th batch is: 9.116924\n",
            "the loss in 24800th batch is: 9.136774\n",
            "the loss in 25000th batch is: 11.059180\n",
            "the loss in 25200th batch is: 9.105024\n",
            "the loss in 25400th batch is: 9.867050\n",
            "the loss in 25600th batch is: 10.315316\n",
            "the loss in 25800th batch is: 9.107005\n",
            "Epoch 8/15\n",
            "the loss in 26000th batch is: 9.056079\n",
            "the loss in 26200th batch is: 9.898263\n",
            "the loss in 26400th batch is: 9.113441\n",
            "the loss in 26600th batch is: 8.785062\n",
            "the loss in 26800th batch is: 9.856471\n",
            "the loss in 27000th batch is: 9.148980\n",
            "Evaluating with val sessions\n",
            "evaluated ID count is 0 / 19007 total\n",
            "evaluated ID count is 1000 / 19007 total\n",
            "evaluated ID count is 2000 / 19007 total\n",
            "evaluated ID count is 3000 / 19007 total\n",
            "evaluated ID count is 4000 / 19007 total\n",
            "evaluated ID count is 5000 / 19007 total\n",
            "evaluated ID count is 6000 / 19007 total\n",
            "evaluated ID count is 7000 / 19007 total\n",
            "evaluated ID count is 8000 / 19007 total\n",
            "evaluated ID count is 9000 / 19007 total\n",
            "evaluated ID count is 10000 / 19007 total\n",
            "evaluated ID count is 11000 / 19007 total\n",
            "evaluated ID count is 12000 / 19007 total\n",
            "evaluated ID count is 13000 / 19007 total\n",
            "evaluated ID count is 14000 / 19007 total\n",
            "evaluated ID count is 15000 / 19007 total\n",
            "evaluated ID count is 16000 / 19007 total\n",
            "evaluated ID count is 17000 / 19007 total\n",
            "evaluated ID count is 18000 / 19007 total\n",
            "evaluated ID count is 19000 / 19007 total\n",
            "#############################################################\n",
            "total clicks: 113704, total purchase:5707\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3158.000000\n",
            "clicks hr ndcg @ 5 : 0.094148, 0.069850\n",
            "purchase hr and ndcg @5 : 0.178202, 0.140640\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 3911.400000\n",
            "clicks hr ndcg @ 10 : 0.118967, 0.077867\n",
            "purchase hr and ndcg @10 : 0.211319, 0.151387\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 4321.200000\n",
            "clicks hr ndcg @ 15 : 0.132194, 0.081367\n",
            "purchase hr and ndcg @15 : 0.230419, 0.156454\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 4627.600000\n",
            "clicks hr ndcg @ 20 : 0.142370, 0.083774\n",
            "purchase hr and ndcg @20 : 0.243561, 0.159558\n",
            "#############################################################\n",
            "the loss in 27200th batch is: 8.632070\n",
            "the loss in 27400th batch is: 9.286509\n",
            "the loss in 27600th batch is: 8.703672\n",
            "the loss in 27800th batch is: 8.701586\n",
            "the loss in 28000th batch is: 9.360992\n",
            "the loss in 28200th batch is: 9.651896\n",
            "the loss in 28400th batch is: 8.769734\n",
            "the loss in 28600th batch is: 9.114221\n",
            "the loss in 28800th batch is: 9.220150\n",
            "the loss in 29000th batch is: 8.774708\n",
            "the loss in 29200th batch is: 8.582117\n",
            "the loss in 29400th batch is: 9.293696\n",
            "the loss in 29600th batch is: 9.185618\n",
            "Epoch 9/15\n",
            "the loss in 29800th batch is: 8.717958\n",
            "the loss in 30000th batch is: 9.489345\n",
            "the loss in 30200th batch is: 8.543810\n",
            "the loss in 30400th batch is: 8.944408\n",
            "the loss in 30600th batch is: 9.325689\n",
            "the loss in 30800th batch is: 8.866737\n",
            "the loss in 31000th batch is: 9.043866\n",
            "the loss in 31200th batch is: 9.120963\n",
            "the loss in 31400th batch is: 8.369454\n",
            "the loss in 31600th batch is: 8.468128\n",
            "the loss in 31800th batch is: 8.398706\n",
            "the loss in 32000th batch is: 8.936262\n",
            "the loss in 32200th batch is: 8.811050\n",
            "the loss in 32400th batch is: 8.732985\n",
            "the loss in 32600th batch is: 8.227760\n",
            "the loss in 32800th batch is: 9.418709\n",
            "the loss in 33000th batch is: 9.128683\n",
            "the loss in 33200th batch is: 8.997576\n",
            "Epoch 10/15\n",
            "the loss in 33400th batch is: 8.752030\n",
            "the loss in 33600th batch is: 9.137471\n",
            "the loss in 33800th batch is: 8.611886\n",
            "the loss in 34000th batch is: 8.895425\n",
            "the loss in 34200th batch is: 8.211167\n",
            "the loss in 34400th batch is: 8.545795\n",
            "the loss in 34600th batch is: 9.007980\n",
            "the loss in 34800th batch is: 8.903114\n",
            "the loss in 35000th batch is: 8.676557\n",
            "the loss in 35200th batch is: 9.696315\n",
            "the loss in 35400th batch is: 8.785361\n",
            "the loss in 35600th batch is: 8.471802\n",
            "the loss in 35800th batch is: 8.024815\n",
            "the loss in 36000th batch is: 8.636790\n",
            "Evaluating with val sessions\n",
            "evaluated ID count is 0 / 19007 total\n",
            "evaluated ID count is 1000 / 19007 total\n",
            "evaluated ID count is 2000 / 19007 total\n",
            "evaluated ID count is 3000 / 19007 total\n",
            "evaluated ID count is 4000 / 19007 total\n",
            "evaluated ID count is 5000 / 19007 total\n",
            "evaluated ID count is 6000 / 19007 total\n",
            "evaluated ID count is 7000 / 19007 total\n",
            "evaluated ID count is 8000 / 19007 total\n",
            "evaluated ID count is 9000 / 19007 total\n",
            "evaluated ID count is 10000 / 19007 total\n",
            "evaluated ID count is 11000 / 19007 total\n",
            "evaluated ID count is 12000 / 19007 total\n",
            "evaluated ID count is 13000 / 19007 total\n",
            "evaluated ID count is 14000 / 19007 total\n",
            "evaluated ID count is 15000 / 19007 total\n",
            "evaluated ID count is 16000 / 19007 total\n",
            "evaluated ID count is 17000 / 19007 total\n",
            "evaluated ID count is 18000 / 19007 total\n",
            "evaluated ID count is 19000 / 19007 total\n",
            "#############################################################\n",
            "total clicks: 113704, total purchase:5707\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 4224.600000\n",
            "clicks hr ndcg @ 5 : 0.126671, 0.095717\n",
            "purchase hr and ndcg @5 : 0.235500, 0.187888\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 5165.200000\n",
            "clicks hr ndcg @ 10 : 0.157347, 0.105665\n",
            "purchase hr and ndcg @10 : 0.278080, 0.201691\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5730.600000\n",
            "clicks hr ndcg @ 15 : 0.176142, 0.110637\n",
            "purchase hr and ndcg @15 : 0.302260, 0.208151\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6137.200000\n",
            "clicks hr ndcg @ 20 : 0.189624, 0.113827\n",
            "purchase hr and ndcg @20 : 0.319783, 0.212283\n",
            "#############################################################\n",
            "the loss in 36200th batch is: 8.187508\n",
            "the loss in 36400th batch is: 8.387737\n",
            "the loss in 36600th batch is: 8.717770\n",
            "the loss in 36800th batch is: 8.769284\n",
            "the loss in 37000th batch is: 8.496799\n",
            "Epoch 11/15\n",
            "the loss in 37200th batch is: 8.288246\n",
            "the loss in 37400th batch is: 8.750743\n",
            "the loss in 37600th batch is: 8.383223\n",
            "the loss in 37800th batch is: 8.552642\n",
            "the loss in 38000th batch is: 8.493393\n",
            "the loss in 38200th batch is: 8.151897\n",
            "the loss in 38400th batch is: 8.653273\n",
            "the loss in 38600th batch is: 8.679770\n",
            "the loss in 38800th batch is: 8.503836\n",
            "the loss in 39000th batch is: 8.008382\n",
            "the loss in 39200th batch is: 8.412182\n",
            "the loss in 39400th batch is: 8.862516\n",
            "the loss in 39600th batch is: 9.574981\n",
            "the loss in 39800th batch is: 8.407226\n",
            "the loss in 40000th batch is: 8.963658\n",
            "the loss in 40200th batch is: 7.948238\n",
            "the loss in 40400th batch is: 9.067696\n",
            "the loss in 40600th batch is: 8.842204\n",
            "Epoch 12/15\n",
            "the loss in 40800th batch is: 8.798180\n",
            "the loss in 41000th batch is: 9.330441\n",
            "the loss in 41200th batch is: 8.792777\n",
            "the loss in 41400th batch is: 9.486575\n",
            "the loss in 41600th batch is: 8.162004\n",
            "the loss in 41800th batch is: 8.359894\n",
            "the loss in 42000th batch is: 8.625943\n",
            "the loss in 42200th batch is: 7.965318\n",
            "the loss in 42400th batch is: 7.904549\n",
            "the loss in 42600th batch is: 8.336604\n",
            "the loss in 42800th batch is: 8.314908\n",
            "the loss in 43000th batch is: 9.162638\n",
            "the loss in 43200th batch is: 8.291971\n",
            "the loss in 43400th batch is: 8.506818\n",
            "the loss in 43600th batch is: 8.781485\n",
            "the loss in 43800th batch is: 7.939394\n",
            "the loss in 44000th batch is: 7.822223\n",
            "the loss in 44200th batch is: 7.481545\n",
            "the loss in 44400th batch is: 8.240002\n",
            "Epoch 13/15\n",
            "the loss in 44600th batch is: 7.848540\n",
            "the loss in 44800th batch is: 8.109277\n",
            "the loss in 45000th batch is: 7.998998\n",
            "Evaluating with val sessions\n",
            "evaluated ID count is 0 / 19007 total\n",
            "evaluated ID count is 1000 / 19007 total\n",
            "evaluated ID count is 2000 / 19007 total\n",
            "evaluated ID count is 3000 / 19007 total\n",
            "evaluated ID count is 4000 / 19007 total\n",
            "evaluated ID count is 5000 / 19007 total\n",
            "evaluated ID count is 6000 / 19007 total\n",
            "evaluated ID count is 7000 / 19007 total\n",
            "evaluated ID count is 8000 / 19007 total\n",
            "evaluated ID count is 9000 / 19007 total\n",
            "evaluated ID count is 10000 / 19007 total\n",
            "evaluated ID count is 11000 / 19007 total\n",
            "evaluated ID count is 12000 / 19007 total\n",
            "evaluated ID count is 13000 / 19007 total\n",
            "evaluated ID count is 14000 / 19007 total\n",
            "evaluated ID count is 15000 / 19007 total\n",
            "evaluated ID count is 16000 / 19007 total\n",
            "evaluated ID count is 17000 / 19007 total\n",
            "evaluated ID count is 18000 / 19007 total\n",
            "evaluated ID count is 19000 / 19007 total\n",
            "#############################################################\n",
            "total clicks: 113704, total purchase:5707\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 4784.000000\n",
            "clicks hr ndcg @ 5 : 0.145421, 0.109554\n",
            "purchase hr and ndcg @5 : 0.258805, 0.205068\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 5848.800000\n",
            "clicks hr ndcg @ 10 : 0.180108, 0.120769\n",
            "purchase hr and ndcg @10 : 0.307167, 0.220648\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 6468.400000\n",
            "clicks hr ndcg @ 15 : 0.201418, 0.126411\n",
            "purchase hr and ndcg @15 : 0.330822, 0.226904\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6925.200000\n",
            "clicks hr ndcg @ 20 : 0.216492, 0.129968\n",
            "purchase hr and ndcg @20 : 0.350797, 0.231611\n",
            "#############################################################\n",
            "the loss in 45200th batch is: 9.468124\n",
            "the loss in 45400th batch is: 9.304803\n",
            "the loss in 45600th batch is: 8.622511\n",
            "the loss in 45800th batch is: 7.645517\n",
            "the loss in 46000th batch is: 7.942863\n",
            "the loss in 46200th batch is: 7.253512\n",
            "the loss in 46400th batch is: 7.590535\n",
            "the loss in 46600th batch is: 7.653474\n",
            "the loss in 46800th batch is: 8.154364\n",
            "the loss in 47000th batch is: 8.273919\n",
            "the loss in 47200th batch is: 8.503692\n",
            "the loss in 47400th batch is: 8.694433\n",
            "the loss in 47600th batch is: 8.479219\n",
            "the loss in 47800th batch is: 7.689207\n",
            "the loss in 48000th batch is: 7.824131\n",
            "the loss in 48200th batch is: 7.729140\n",
            "Epoch 14/15\n",
            "the loss in 48400th batch is: 7.613657\n",
            "the loss in 48600th batch is: 7.449791\n",
            "the loss in 48800th batch is: 7.580440\n",
            "the loss in 49000th batch is: 7.574094\n",
            "the loss in 49200th batch is: 8.628380\n",
            "the loss in 49400th batch is: 8.356226\n",
            "the loss in 49600th batch is: 7.810279\n",
            "the loss in 49800th batch is: 7.994160\n",
            "the loss in 50000th batch is: 8.009359\n",
            "the loss in 50200th batch is: 8.096203\n",
            "the loss in 50400th batch is: 7.870318\n",
            "the loss in 50600th batch is: 8.727034\n",
            "the loss in 50800th batch is: 8.075061\n",
            "the loss in 51000th batch is: 8.194380\n",
            "the loss in 51200th batch is: 8.012719\n",
            "the loss in 51400th batch is: 7.801734\n",
            "the loss in 51600th batch is: 7.617857\n",
            "the loss in 51800th batch is: 7.697555\n",
            "Epoch 15/15\n",
            "the loss in 52000th batch is: 8.351906\n",
            "the loss in 52200th batch is: 8.414771\n",
            "the loss in 52400th batch is: 7.485642\n",
            "the loss in 52600th batch is: 7.882361\n",
            "the loss in 52800th batch is: 7.539655\n",
            "the loss in 53000th batch is: 7.313058\n",
            "the loss in 53200th batch is: 7.812822\n",
            "the loss in 53400th batch is: 8.730419\n",
            "the loss in 53600th batch is: 7.964533\n",
            "the loss in 53800th batch is: 8.284650\n",
            "the loss in 54000th batch is: 7.999247\n",
            "Evaluating with val sessions\n",
            "evaluated ID count is 0 / 19007 total\n",
            "evaluated ID count is 1000 / 19007 total\n",
            "evaluated ID count is 2000 / 19007 total\n",
            "evaluated ID count is 3000 / 19007 total\n",
            "evaluated ID count is 4000 / 19007 total\n",
            "evaluated ID count is 5000 / 19007 total\n",
            "evaluated ID count is 6000 / 19007 total\n",
            "evaluated ID count is 7000 / 19007 total\n",
            "evaluated ID count is 8000 / 19007 total\n",
            "evaluated ID count is 9000 / 19007 total\n",
            "evaluated ID count is 10000 / 19007 total\n",
            "evaluated ID count is 11000 / 19007 total\n",
            "evaluated ID count is 12000 / 19007 total\n",
            "evaluated ID count is 13000 / 19007 total\n",
            "evaluated ID count is 14000 / 19007 total\n",
            "evaluated ID count is 15000 / 19007 total\n",
            "evaluated ID count is 16000 / 19007 total\n",
            "evaluated ID count is 17000 / 19007 total\n",
            "evaluated ID count is 18000 / 19007 total\n",
            "evaluated ID count is 19000 / 19007 total\n",
            "#############################################################\n",
            "total clicks: 113704, total purchase:5707\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5441.400000\n",
            "clicks hr ndcg @ 5 : 0.163776, 0.123592\n",
            "purchase hr and ndcg @5 : 0.300859, 0.239322\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6601.200000\n",
            "clicks hr ndcg @ 10 : 0.202113, 0.136014\n",
            "purchase hr and ndcg @10 : 0.351323, 0.255750\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7283.200000\n",
            "clicks hr ndcg @ 15 : 0.224627, 0.141973\n",
            "purchase hr and ndcg @15 : 0.381111, 0.263647\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7746.400000\n",
            "clicks hr ndcg @ 20 : 0.240642, 0.145756\n",
            "purchase hr and ndcg @20 : 0.398458, 0.267748\n",
            "#############################################################\n",
            "the loss in 54200th batch is: 8.516202\n",
            "the loss in 54400th batch is: 7.693968\n",
            "the loss in 54600th batch is: 7.939243\n",
            "the loss in 54800th batch is: 7.656770\n",
            "the loss in 55000th batch is: 7.431769\n",
            "the loss in 55200th batch is: 7.468093\n",
            "the loss in 55400th batch is: 7.861225\n",
            "the loss in 55600th batch is: 7.904967\n",
            "Finished training\n",
            "Evaluating with test sessions\n",
            "evaluated ID count is 0 / 19007 total\n",
            "evaluated ID count is 1000 / 19007 total\n",
            "evaluated ID count is 2000 / 19007 total\n",
            "evaluated ID count is 3000 / 19007 total\n",
            "evaluated ID count is 4000 / 19007 total\n",
            "evaluated ID count is 5000 / 19007 total\n",
            "evaluated ID count is 6000 / 19007 total\n",
            "evaluated ID count is 7000 / 19007 total\n",
            "evaluated ID count is 8000 / 19007 total\n",
            "evaluated ID count is 9000 / 19007 total\n",
            "evaluated ID count is 10000 / 19007 total\n",
            "evaluated ID count is 11000 / 19007 total\n",
            "evaluated ID count is 12000 / 19007 total\n",
            "evaluated ID count is 13000 / 19007 total\n",
            "evaluated ID count is 14000 / 19007 total\n",
            "evaluated ID count is 15000 / 19007 total\n",
            "evaluated ID count is 16000 / 19007 total\n",
            "evaluated ID count is 17000 / 19007 total\n",
            "evaluated ID count is 18000 / 19007 total\n",
            "evaluated ID count is 19000 / 19007 total\n",
            "#############################################################\n",
            "total clicks: 110130, total purchase:5227\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5299.000000\n",
            "clicks hr ndcg @ 5 : 0.171025, 0.129988\n",
            "purchase hr and ndcg @5 : 0.293094, 0.232987\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6446.600000\n",
            "clicks hr ndcg @ 10 : 0.212413, 0.143371\n",
            "purchase hr and ndcg @10 : 0.338244, 0.247667\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7113.000000\n",
            "clicks hr ndcg @ 15 : 0.236085, 0.149640\n",
            "purchase hr and ndcg @15 : 0.365984, 0.255026\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7581.200000\n",
            "clicks hr ndcg @ 20 : 0.252574, 0.153531\n",
            "purchase hr and ndcg @20 : 0.386072, 0.259763\n",
            "#############################################################\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf \n",
        "%cd '{RR_DIR}/src'\n",
        "with tf.device('/GPU:0'):\n",
        "  ! python SNQN_new.py --model=GRU --epoch=15 --data='{RR_DIR}/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buFHY9iI7PRj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
